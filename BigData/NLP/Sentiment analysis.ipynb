{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "import glove\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1cb0e",
   "metadata": {},
   "source": [
    "# Define new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        t = \"\" if t == \"RT\" else t\n",
    "        new_text.append(t)\n",
    "    \n",
    "    sentence = \" \".join(new_text)\n",
    "    sentence = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', sentence)\n",
    "    sentence = re.sub(\"\\.\\.\\.\", '', sentence)\n",
    "    sentence = re.sub(\"\\.\\.\", '', sentence)\n",
    "    sentence = re.sub(\"#\", '', sentence)\n",
    "    \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1014e1",
   "metadata": {},
   "source": [
    "# Get file info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the BERT folder\n",
    "results = glob('../raw/Full/*.csv')\n",
    "results.sort()\n",
    "\n",
    "f = open(\"corpus_full.json\")\n",
    "corpus_full = json.load(f)\n",
    "f.close()\n",
    "\n",
    "full_raw = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf2ddf",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained sentiment model\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path, use_fast = True)\n",
    "\n",
    "# Get pretrained models\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dict\n",
    "with open('bert_sentiment.pickle', 'rb') as filename:\n",
    "    sentiment = pickle.load(filename)\n",
    "\n",
    "# Open dict\n",
    "with open('bert_sentiment_overall.pickle', 'rb') as filename:\n",
    "    sentiment_overall = pickle.load(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c73c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results[len(sentiment.keys())-1:]:\n",
    "    day = r[-14:-4]\n",
    "    print(day)\n",
    "    if day not in sentiment.keys():\n",
    "        sentiment[day] = {}\n",
    "    if day not in sentiment_overall.keys():\n",
    "        sentiment_overall[day] = []\n",
    "\n",
    "    sentiment[day]['sentence'] = []\n",
    "    sentiment[day]['sentiment'] = []\n",
    "    overall = 0\n",
    "    \n",
    "    df = pd.read_csv(r, lineterminator='\\n')\n",
    "    df = df[df.lemma_length > 0]\n",
    "    corpus = df.text.tolist()\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence = preprocess(sentence)\n",
    "        sentiment[day]['sentence'].append(sentence)\n",
    "\n",
    "        encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        # Get sentence sentiment\n",
    "        # Positive words are 0.5, negative -0.5, neutral is 0\n",
    "        # Take the sum, the larger the sum the more positive the sentence\n",
    "        total = 0\n",
    "        for index, label in config.id2label.items():\n",
    "            if label == \"negative\":\n",
    "                total += -0.5\n",
    "            elif label == \"neutral\":\n",
    "                total += 0\n",
    "            elif label == \"positive\":\n",
    "                total += 0.5\n",
    "\n",
    "        if total > 0:\n",
    "            sentiment[day]['sentiment'].append(\"POS\")\n",
    "            overall += 0.5\n",
    "        elif total < 0:\n",
    "            sentiment[day]['sentiment'].append(\"NEG\")\n",
    "            overall += -0.5\n",
    "        else:\n",
    "            sentiment[day]['sentiment'].append(\"NEU\")\n",
    "            overall += 0\n",
    "    \n",
    "    if overall > 0:\n",
    "        sentiment_overall[day] = \"POS\"\n",
    "    elif overall < 0:\n",
    "        sentiment_overall[day] = \"NEG\"\n",
    "    else:\n",
    "        sentiment_overall[day] = \"NEU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bert_sentiment.pickle', 'wb') as filename:\n",
    "    pickle.dump(sentiment, filename)\n",
    "with open('bert_sentiment_overall.pickle', 'wb') as filename:\n",
    "    pickle.dump(sentiment_overall, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame.from_dict({(i,j): sentiment[i][j]\n",
    "                               for i in sentiment.keys()\n",
    "                               for j in sentiment[i].keys()}, \n",
    "                              orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_overall_df = pd.DataFrame.from_dict(sentiment_overall, \n",
    "                              orient=\"index\")\n",
    "sentiment_overall_df = sentiment_overall_df.reset_index()\n",
    "sentiment_overall_df.columns = [\"day\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f5922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06658dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be3d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715554c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2227a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
