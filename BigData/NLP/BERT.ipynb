{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13292529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Create an empty dict to store embeddings\n",
    "# # # embeddings_full = {}\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True, \n",
    "                                          padding='max_length', \n",
    "                                          truncation=True)\n",
    "\n",
    "# Get the stereotypes we are interested in\n",
    "f = open(\"stereotypes.json\")\n",
    "stereotypes = json.load(f)\n",
    "f.close()\n",
    "\n",
    "# List all files in the BERT folder\n",
    "results = glob('../raw/BERT/*.csv')\n",
    "\n",
    "# Open dict\n",
    "with open('bert_embeddings.pickle', 'rb') as filename:\n",
    "    embeddings_full = pickle.load(filename)\n",
    "    \n",
    "# embeddings_full.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc610572",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results[len(embeddings_full.keys())-1:]:\n",
    "    day = r[-14:-4]\n",
    "    df = pd.read_csv(r, lineterminator='\\n')\n",
    "    df = df[df.lemma_length > 0]\n",
    "    corpus = df.bert_lemma.tolist()\n",
    "    if day not in embeddings_full.keys():\n",
    "        embeddings_full[day] = {}\n",
    "    embeddings_full[day]['database'] = []\n",
    "    embeddings_full[day]['category'] = []\n",
    "    embeddings_full[day]['word'] = []\n",
    "    embeddings_full[day]['vectors'] = []\n",
    "    for sentence in corpus:\n",
    "        # Tokenize our sentence with the BERT tokenizer.\n",
    "        tokenized_text = tokenizer.tokenize(sentence)\n",
    "\n",
    "        # Map the token strings to their vocabulary indices.\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "        # Load pre-trained model (weights)\n",
    "        model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                          output_hidden_states = True) # Whether the model returns all hidden-states.\n",
    "\n",
    "        # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "        model.eval()\n",
    "\n",
    "        # Run the text through BERT, and collect all of the hidden states produced from all 12 layers. \n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "            # Evaluating the model will return a different number of objects based on how it's  configured in the `from_pretrained` call earlier\n",
    "            # In this case, becase we set `output_hidden_states = True`, the third item will be the hidden states from all layers\n",
    "            # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "            # Concatenate the tensors for all layers. We use `stack` here to create a new dimension in the tensor.\n",
    "            token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "            # Remove dimension 1, the \"batches\".\n",
    "            token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "            # Swap dimensions 0 and 1.\n",
    "            token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "            # Stores the token vectors with different shape, concatenating the last 4 layers\n",
    "            token_vecs_cat = []\n",
    "\n",
    "            for token in token_embeddings:\n",
    "\n",
    "                # For each token in the sentence, concatenate the vectors from the last four layers\n",
    "                cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "                # Use `cat_vec` to represent `token`.\n",
    "                token_vecs_cat.append(cat_vec)\n",
    "\n",
    "        for i in np.arange(len(tokenized_text)):\n",
    "            for key, value in stereotypes.items():\n",
    "                if tokenized_text[i] in ['Asians', 'asians', 'Asian', 'asian', 'Chinese', 'chinese', 'White', 'white', 'Black', 'black', 'Hispanic', 'hispanic', 'Latino', 'latino', 'Latina', 'latina', 'Latinx', 'latinx', 'Latine', 'latine']: \n",
    "                    embeddings_full[day]['database'].append('bert')\n",
    "                    embeddings_full[day]['category'].append('Group')\n",
    "                    embeddings_full[day]['word'].append(tokenized_text[i])\n",
    "                    embeddings_full[day]['vectors'].append(token_vecs_cat[i])\n",
    "                elif tokenized_text[i] in value:\n",
    "                    embeddings_full[day]['database'].append('bert')\n",
    "                    embeddings_full[day]['category'].append(key)\n",
    "                    embeddings_full[day]['word'].append(tokenized_text[i])\n",
    "                    embeddings_full[day]['vectors'].append(token_vecs_cat[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f169627",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bert_embeddings.pickle', 'wb') as filename:\n",
    "    pickle.dump(embeddings_full, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_full.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5c22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8271fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_vecs_sum = []\n",
    "\n",
    "# for token in token_embeddings:\n",
    "\n",
    "    # Sum the vectors from the last four layers\n",
    "    # sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`\n",
    "    # token_vecs_sum.append(sum_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16bd78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b014ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ea194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
